{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"colab":{"name":"FoIL_TP13.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Al77RuJX3ilU"},"source":["# EE-411 Fundamentals of inference and learning\n","\n","## Exercise session 13: Autoencoder, denoising and K-means\n","\n","In the first part of this set of exercises we will write an Auto-encoder in Python using Keras, and we will apply it for a denoising problem, evaluating its performance in different situations. In the second part we will have a simple implementation of the K-means method for clustering using scikit-learn.\n","\n","**What you will learn today:** In this notebook, we will use an alternative to Pytorch: Keras. Specifically, we will use it to implement an Autoencoder. Then, we will see how to do clustering with K-means using scikit-learn.\n"]},{"cell_type":"markdown","metadata":{"id":"Hdovsgj6DKiA"},"source":["# 1) Autoencoder"]},{"cell_type":"markdown","metadata":{"id":"sliMd6G96FoY"},"source":["An autoencoder, autoassociator or Diabolo network is an artificial neural network whose aim is to learn a representation (or an *encoding*) for a set of data, often for the purpose of dimensionality reduction. Recently, the autoencoder concept has become more widely used for denoising images, and we shall illustrate these in this notebook on the MNIST dataset. \n","\n","First, let us look download the images from the MNIST dataset, and look at some of them."]},{"cell_type":"code","metadata":{"scrolled":true,"id":"Lv9rggpD3ilW"},"source":["from keras.datasets import mnist\n","import numpy as np\n","#We load the data\n","(x_train, _), (x_test, _) = mnist.load_data()\n","#We renormalize the data to a float in [0,1]\n","x_train = x_train.astype('float32') / 255.\n","x_test = x_test.astype('float32') / 255.\n","#We reshape the images to be 2d matrices of dimension n times d\n","x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n","x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n","print(x_train.shape)\n","print(x_test.shape)\n","#We plot the first ten images\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","n = 10\n","plt.figure(figsize=(20, 2))\n","for i in range(n):\n","    ax = plt.subplot(1, n, i+1)\n","    plt.imshow(x_test[i].reshape(28, 28))\n","    plt.gray()\n","    ax.get_xaxis().set_visible(False)\n","    ax.get_yaxis().set_visible(False)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dSn9FI_K3ilX"},"source":["Let us define our autoencoder using Keras. If you already know how to work with Pytorch, this will be very intuitive. \n","\n","**First** we encode data by a first neural network that goes from the $784$ points to $128$, then $64$ and finally $32$. \n","\n","**Second** we write the decoder that performs the same operation, in reverse.\n","\n","**Third** we can build our model and compile it,"]},{"cell_type":"code","metadata":{"id":"AqChSjC53ilX"},"source":["from keras.layers import Input, Dense\n","from keras.models import Model\n","input_img = Input(shape=(784,))\n","#Encoding\n","encoded = Dense(128, activation='relu')(input_img)\n","encoded = Dense(64, activation='relu')(encoded)\n","encoded = Dense(32, activation='relu')(encoded)\n","#Decoding\n","decoded = Dense(64, activation='relu')(encoded)\n","decoded = Dense(128, activation='relu')(decoded)\n","decoded = Dense(784, activation='sigmoid')(decoded)\n","#Putting all together\n","autoencoder_mlp = Model(input_img, decoded)\n","autoencoder_mlp.compile(optimizer='adam', loss='binary_crossentropy')\n","autoencoder_mlp.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2E1QrCy23ilX"},"source":["We now run the training for $100$ epochs. This takes some time because there are a lot of paramteres to learn. On a K80 GPU it takes 1sec/epoch, but on a standard CPU it is about 6sec/epoch."]},{"cell_type":"code","metadata":{"id":"R07w-uUZ3ilX"},"source":["#Training the model -- CAN BE SKIPPED TO SAVE TIME\n","history_mlp = autoencoder_mlp.fit(x_train, x_train,\n","                epochs=500,\n","                batch_size=256,\n","                shuffle=True,\n","                validation_data=(x_test, x_test))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"siARnYA63ilY"},"source":["# Plot history for accuracy\n","plt.plot(history_mlp.history['loss'])\n","plt.plot(history_mlp.history['val_loss'])\n","plt.title('model loss -- MLP autoencoder')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper right')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"88ZTGqPD3ilY"},"source":["# SAVE/READ THE WEIGHTS FROM FILE\n","autoencoder_mlp.save_weights(\"dense_autoencoder.h5\")\n","#autoencoder_mlp.load_weights(\"dense_autoencoder.h5\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FuNXw-nY3ilZ"},"source":["Now, it is time to see the result of the learning process. \n","\n","Let us create an \"encoder\" model with the weights that we have learned, that outputs the result of the middle layer, and records the images corresponding to the test set observed after compression:"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"NTSAswCk3ilZ"},"source":["encoder = Model(input_img, encoded)\n","encoded_imgs = encoder.predict(x_test)\n","print(encoded_imgs.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jBeuV33j3ila"},"source":["We now do the same, but for the full autoencoder:"]},{"cell_type":"code","metadata":{"id":"7KV9NPCi3ila"},"source":["decoded_imgs = autoencoder_mlp.predict(x_test)\n","print(decoded_imgs.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_iV6e-DB3ila"},"source":["Let us see how it looks:"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"sWVv_rW73ila"},"source":["n = 10  # how many digits we will display\n","plt.figure(figsize=(20, 6))\n","for i in range(n):\n","    # display original\n","    ax = plt.subplot(3, n, i + 1)\n","    plt.imshow(x_test[i].reshape(28, 28))\n","    plt.gray()\n","    ax.get_xaxis().set_visible(False)\n","    ax.get_yaxis().set_visible(False)\n","\n","    # display reconstruction\n","    ax = plt.subplot(3, n, i + 1 + n)\n","    plt.imshow(encoded_imgs[i].reshape(8,4))\n","    plt.gray()\n","    ax.get_xaxis().set_visible(False)\n","    ax.get_yaxis().set_visible(False)\n","    \n","    # display reconstruction\n","    ax = plt.subplot(3, n, i + 1 + n + n )\n","    plt.imshow(decoded_imgs[i].reshape(28, 28))\n","    plt.gray()\n","    ax.get_xaxis().set_visible(False)\n","    ax.get_yaxis().set_visible(False)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"21x9Ysd0Kvw1"},"source":["len(encoded_imgs)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RQRzd4G73ila"},"source":["This is quite nice, and indeed we see that we can recognize images quite easily. We can also have a look at the 32-dimensional encoded representations in the middle. Notice how the two \"one\" are coded similarly, as well as the two \"four\"."]},{"cell_type":"markdown","metadata":{"id":"ek0SRUOi3ila"},"source":["### Convolutional auto-encoder\n","\n","Now we are going to build the autoencoer only with cnn:"]},{"cell_type":"code","metadata":{"id":"CLj_W8Ue3ilb"},"source":["from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n","from keras.models import Model\n","from keras import backend as K\n","\n","input_img = Input(shape=(28, 28, 1))  \n","\n","x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n","x = MaxPooling2D((2, 2), padding='same')(x)\n","x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n","x = MaxPooling2D((2, 2), padding='same')(x)\n","x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n","encoded = MaxPooling2D((2, 2), padding='same')(x)\n","\n","# After the encoding, the representation is (4, 4, 8) (128-dimensional)\n","\n","x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n","x = UpSampling2D((2, 2))(x)\n","x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n","x = UpSampling2D((2, 2))(x)\n","x = Conv2D(16, (3, 3), activation='relu')(x)\n","x = UpSampling2D((2, 2))(x)\n","decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n","\n","autoencoder_cnn = Model(input_img, decoded)\n","autoencoder_cnn.compile(optimizer='adam', loss='binary_crossentropy')\n","autoencoder_cnn.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CH5K9hHi3ilb"},"source":["Since we are using cnn layers, images should be kept as two-dimensional arrays. Once this is done, we repeat the fitting operation. It takes about 5s by epoch on a K80 GPU."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"Kuzb6h183ilb"},"source":["(x_train, _), (x_test, _) = mnist.load_data()\n","\n","x_train = x_train.astype('float32') / 255.\n","x_test = x_test.astype('float32') / 255.\n","x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))  # adapt this if using `channels_first` image data format\n","x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))  # adapt this if using `channels_first` image data format"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1) Train the model as before (If it takes too much time, use the cnn_autoencoder.h5 file in the repo)"],"metadata":{"id":"99eCPV6kAVOR"}},{"cell_type":"code","metadata":{"id":"CdwfWUaM3ilb"},"source":["### YOUR CODE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 2) Plot history for accuracy"],"metadata":{"id":"gtRwYhsrAqiQ"}},{"cell_type":"code","metadata":{"id":"2yESbi0b3ilb"},"source":["### YOUR CODE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"p_dwxYd93ilc"},"source":["##### 3) Display the reconstructed images and compare them to the original ones. Display also the encoded representations as before"]},{"cell_type":"code","metadata":{"id":"8-JPOMs83ilc"},"source":["### YOUR CODE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7NaAtv043ilc"},"source":["## Denoising with auto-encoders\n","\n","### Noisy images\n","\n","Now, we shall use our auto-encoders for denoising. We will train the autoencoder to map noisy images to clean ones. This will be done by applying a gaussian noise (and clip the images between 0 and 1) to the training set."]},{"cell_type":"code","metadata":{"id":"_ggWuDQ03ilc"},"source":["from keras.datasets import mnist\n","import numpy as np\n","(x_train, _), (x_test, _) = mnist.load_data()\n","\n","x_train = x_train.astype('float32') / 255.\n","x_test = x_test.astype('float32') / 255.\n","x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n","x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n","print(x_train.shape)\n","print(x_test.shape)\n","\n","noise_factor = 0.5\n","x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \n","x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) \n","\n","x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n","x_test_noisy = np.clip(x_test_noisy, 0., 1.)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WjMAy5OW3ilc"},"source":["Let us see how these looks:"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"DBEhKdYp3ilc"},"source":["import matplotlib.pyplot as plt\n","n = 10\n","plt.figure(figsize=(20, 2))\n","for i in range(n):\n","    ax = plt.subplot(1, n, i+1)\n","    plt.imshow(x_test_noisy[i].reshape(28, 28))\n","    plt.gray()\n","    ax.get_xaxis().set_visible(False)\n","    ax.get_yaxis().set_visible(False)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hTXkMZso3ilc"},"source":["### Dense denoiser\n","\n","##### 4) Using the simple dense network we defined above, train it on the noisy data"]},{"cell_type":"code","metadata":{"id":"PuOaojeR3ilc"},"source":["### YOUR CODE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 5) Plot history for accuracy. Then, compare the reconstructed images to the original (noisy) ones."],"metadata":{"id":"mbwyiGe2CA4Z"}},{"cell_type":"code","metadata":{"collapsed":true,"id":"lRzrlGsE3ilc"},"source":["### YOUR CODE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f01hGs3V3ild"},"source":["### CNN denoiser\n","\n","In order to improve the quality of the reconstruction, we shall use a CNN with more filters per layer..."]},{"cell_type":"code","metadata":{"id":"AeTiD8dL3ild"},"source":["# Reshape the images to use a CNN\n","x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))  \n","x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))  \n","x_train_noisy = np.reshape(x_train_noisy, (len(x_train_noisy), 28, 28, 1))  \n","x_test_noisy = np.reshape(x_test_noisy, (len(x_test_noisy), 28, 28, 1))  \n","\n","input_img = Input(shape=(28, 28, 1))  # adapt this if using `channels_first` image data format\n","\n","x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n","x = MaxPooling2D((2, 2), padding='same')(x)\n","x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n","encoded = MaxPooling2D((2, 2), padding='same')(x)\n","\n","# Here this point the representation is (7, 7, 32)\n","\n","x = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n","x = UpSampling2D((2, 2))(x)\n","x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n","x = UpSampling2D((2, 2))(x)\n","decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n","\n","denoiser_cnn = Model(input_img, decoded)\n","denoiser_cnn.compile(optimizer='adam', loss='binary_crossentropy')\n","denoiser_cnn.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Fz-Zv7on3ild"},"source":["... and train it a bit longer (8sec/epoch on a GPU)."]},{"cell_type":"markdown","source":["##### 5) Plot history for accuracy. Then, compare the reconstructed images to the original (noisy) ones."],"metadata":{"id":"tNcGnLGLCa-_"}},{"cell_type":"code","source":["### YOUR CODE"],"metadata":{"id":"TA2SlFObCh8G"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B_oOGFWrDhrO"},"source":["# 2) K-means"]},{"cell_type":"markdown","metadata":{"id":"XLLS_BRU2Yhc"},"source":["Now we come back to scikit-learn to see how to easily implement K-means "]},{"cell_type":"markdown","metadata":{"id":"EAdtWVSY1jra"},"source":["*1. Generate K Gaussian clusters of $n$ samples. Each cluster has $n_k = n/K$ data points $\\boldsymbol{x}^{\\mu}_{i,k} \\in \\mathbb{R}^{d}$ of mean  $\\mu_k \\in \\mathbb{R}^{d}$, and covariance matrix  $\\Sigma = \\sigma \\mathbb{I}_{d\\times d}$. Take $d = 2$. Plot the data points in the 2-dimensional space with their centroids and assign to each data point a color according to cluster membership.*\n","\n","\n","Hint 1: for example, you can choose $n_k=100$, $K=3$ and $\\sigma=1$. Try fixing some well-distanced centroids for this first part."]},{"cell_type":"code","source":["#Hint 2: Use the following function to get the distance of a point from a center\n","\n","def distance_from_the_center(X, m):\n","  \"\"\"\n","  This function assign to each example in X a label according to its distance from the center.\n","  Input:  X = data;\n","          m = centroids.\n","  Output: cluster_membership = array of length #of samples, containing the label reffering to the cluster to which examples in X belongs to;\n","          cost = sum of the square distances of each data point from its cluster \n","  \"\"\"\n","\n","  cluster_membership = np.zeros(len(X)) # initialize an empty array of length = number of samples\n","  cost = 0. # initialize the cost function\n","  for mu in range(len(X)): # loop over all examples\n","    distances = np.zeros(K) # initialize an empty array of length = input dimension where to store all the distances a given example has from each centroid\n","    for k in range(K): # loop over all the clusters\n","      dist = np.linalg.norm(X[mu] - m[k]) # compute the square distance of an example mu from centroid k \n","      distances[k] = dist # store the corresponding result in the array of distances\n","    cluster_membership[mu] = np.argmin(distances) # assign to the example a label referring to the closest cluster \n","    cost += np.min(distances**2) # compute the cost function\n","  return cluster_membership, cost "],"metadata":{"id":"Iq0MqE6WCrvP"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JD0O268s25zq"},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib\n","import random"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IUE88dNNmr40"},"source":["### YOUR CODE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HK4ZOV4YyHHl"},"source":["*2. Implement K-Means using the built-in methods from scikit-learn. You can use [this website](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) as a reference (by now you should be able to use scikit learn confidently). Plot the data points in the 2-dimensional space with their centroids and compare these to the predicted ones.*\n","\n","Hint: You can use *Kmeans.cluster_centers_* and *Kmeans.labels_* to extract the means and the variances resepectively"]},{"cell_type":"code","source":["### YOUR CODE"],"metadata":{"id":"XXhaH11yC9vh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XXnDJJSW_RN5"},"source":["*3. Vary the variance $\\sigma$ of each cluster in $[0.1,100.]$ and plot the detected cluster again with their centroids and colors assigned according to cluster membership. In which way are the predictions affected when the noise level is higher?*"]},{"cell_type":"code","source":["### YOUR CODE"],"metadata":{"id":"Lmr_r_PDDHyG"},"execution_count":null,"outputs":[]}]}
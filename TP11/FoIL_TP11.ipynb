{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning tips and tricks: Data augmentation and Transfer learning\n",
    "\n",
    "**What you will learn today**: You will learn how to improve the performance of a deep neural network by increasing the effective data available for training using data augmentation. You will also learn how to leverage large pretrained models to boost the performance of a downstream task using transfer learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On the previous episode...\n",
    "\n",
    "On the previous lab we explored different techniques to train neural networks and implemented them using `PyTorch`. Our experiments showed that choosing the right learning rate and architecture are fundamental to generalize on a complex dataset such as CIFAR10. We learned how modern optimizers work, and explored new architectural concepts such as batch normalization and skip connections.\n",
    "\n",
    "In this lab, we will continue this journey and investigate other techniques to improve performance of a neural network. In particular, we will see how one can exploit the flexibility of stochastic gradient descent to increase our effective data available, and how we can leverage large pretrained models to initialize our networks in a smart way.\n",
    "\n",
    "Specifically, we will talk about:\n",
    "* Data augmentation\n",
    "* Transfer learning\n",
    "\n",
    "So... let's get started!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, we copy-paste the necessary code from the previous lab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "class BasicModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Here we define the model modules\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # defines the forward function of the model. \n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "    def fit(self, train_dataloader, optimizer, epochs, device, plot_loss=True):\n",
    "        losses = []\n",
    "        for epoch in range(epochs):\n",
    "            running_loss = self.train_epoch(\n",
    "                train_dataloader=train_dataloader, \n",
    "                optimizer=optimizer, \n",
    "                epoch_idx=epoch,\n",
    "                device=device)\n",
    "            \n",
    "            losses.extend(running_loss)\n",
    "\n",
    "        if plot_loss:\n",
    "            self.plot_loss_progression(losses=losses)\n",
    "\n",
    "    def plot_loss_progression(self, losses):\n",
    "        plt.plot(losses)\n",
    "        plt.xlabel('Steps')\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Loss progression across steps\")\n",
    "\n",
    "    def train_epoch(self, train_dataloader, optimizer, epoch_idx, device):\n",
    "        epoch_losses = []\n",
    "        running_loss = 0.0\n",
    "\n",
    "        self.train()\n",
    "        tk0 = tqdm(train_dataloader, total=len(train_dataloader), desc=f\"Epoch {epoch_idx}\")\n",
    "        for batch_idx, (data, target) in enumerate(tk0):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            output = self(data)\n",
    "            loss = F.cross_entropy(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            avg_loss = running_loss / (batch_idx + 1)\n",
    "            tk0.set_postfix(loss=avg_loss, stage=\"train\")\n",
    "            epoch_losses.append(loss.item())\n",
    "\n",
    "        \n",
    "        return epoch_losses\n",
    "\n",
    "\n",
    "    def predict(self, test_dataloader, device):\n",
    "        self.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_dataloader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "\n",
    "                output = self(data)\n",
    "                loss = F.cross_entropy(output, target)\n",
    "                test_loss += loss.item()\n",
    "                pred = output.data.max(1, keepdim=True)[1]\n",
    "                correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "\n",
    "        test_loss /= len(test_dataloader.dataset)\n",
    "        accuracy = 100. * correct / len(test_dataloader.dataset)\n",
    "\n",
    "        print(f'Test set: Avg. loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_dataloader.dataset)} ({accuracy:.0f}%)')\n",
    "\n",
    "\n",
    "def show(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(BasicModel):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes \n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every model we want to create, we will create a new class that inherits `BasicModel` and implemements the `__init__` and `forward` functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation\n",
    "Data augmentation is a training technique which consists in transforming every batch of data shown to the model using some random operation which generates a new ''view'' of each sample that retains its semantic information. For example, in the context of image classification, the label of most objects remains the same if you mirror them horizontally. Therefore, a cheap way to increase your training data, is to ''augment'' each sample by introducing its mirrored counterpart.\n",
    "\n",
    "Let's do it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we load all the necessary libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `PyTorch`, the data augmentation operations are included in the transformation pipeline of a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.RandomHorizontalFlip() # We want to randomly apply a random flip to every sample\n",
    "])\n",
    "\n",
    "# We do not want to augment the test data, so we need a different transform pipeline\n",
    "test_transform = T.Compose([\n",
    "    T.ToTensor(), \n",
    "])\n",
    "\n",
    "# load the train dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data/', \n",
    "    train=True, \n",
    "    download=True,\n",
    "    transform=train_transform)\n",
    "\n",
    "# load the test dataset\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data/', \n",
    "    train=False, \n",
    "    download=True,\n",
    "    transform=test_transform)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `PyTorch`, any `nn.Module` can be included in a transform pipeline. Every time you ask for a sample `x`, `PyTorch` calls `transform.forward(x)` before feeding it to the model. This means we can easily visualize the effect of data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im, _ = test_dataset[0]\n",
    "im = im[None, ...] # We need a leading batch dimension to feed to the model\n",
    "\n",
    "images_rot = torch.cat([T.RandomHorizontalFlip()(im) for _ in range(10)])\n",
    "\n",
    "\n",
    "grid = torchvision.utils.make_grid(images_rot, nrow=5, padding=2)\n",
    "show(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Horizontal flips are a bit obvious. We can get more creative with data augmentation. However, bare in mind that some transformations might destroy important information of your data, so be careful when applying it.\n",
    "\n",
    "CIFAR10 is relatively easy, so the following transformations are enough to achieve good performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomCrop(size=[32,32], padding=4)\n",
    "])\n",
    "\n",
    "# We do not want to augment the test data, so we need a different transform pipeline\n",
    "test_transform = T.Compose([\n",
    "    T.ToTensor(), \n",
    "])\n",
    "\n",
    "# load the train dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data/', \n",
    "    train=True, \n",
    "    download=True,\n",
    "    transform=train_transform)\n",
    "\n",
    "# load the test dataset\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data/', \n",
    "    train=False, \n",
    "    download=True,\n",
    "    transform=test_transform)\n",
    "\n",
    "# we make the Batch_sizes smaller for computational reasons\n",
    "# we will later use larger models and memory might become an issue\n",
    "BATCH_SIZE = 256\n",
    "TEST_BATCH_SIZE = 256\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True, \n",
    "    num_workers=2)\n",
    "\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset, \n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False, \n",
    "    num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = ResNet(block=Block, num_blocks=[2,2,2,2]).to(DEVICE)\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# train the ResNet\n",
    "model.fit(\n",
    "    train_dataloader = train_dataloader,\n",
    "    optimizer = optimizer,\n",
    "    epochs = 30,\n",
    "    device = DEVICE\n",
    ")\n",
    "\n",
    "# predict with the trained model\n",
    "model.predict(\n",
    "    test_dataloader = test_dataloader,\n",
    "    device = DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning\n",
    "\n",
    "In practice, very few people train an entire Convolutional Network from scratch (with random initialization), because it is relatively rare to have a dataset of sufficient size. Instead, it is common to pretrain a ConvNet on a very large dataset (e.g. ImageNet, which contains 1.2 million images with 1000 categories), and then use the ConvNet either as an initialization or a fixed feature extractor for the task of interest.\n",
    "\n",
    "Transfer learning refers to the concept of initializing a neural network using the weights learned on a different task before training. Surprisingly, if the pretraining dataset is large enough, but also semantically ''close'' to the downstream task, using transfer learning, instead of regular training from random weights can significantly boost performance. Intuitively, transfer learning allows to recycle the features learned with a lot of data on the pretraining task, and leverage them to classify a new dataset.\n",
    "\n",
    "Let's see this in practice. To that end, we will follow the [PyTorch tutorial on transfer learning](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html), which is an excellent resource to learn how to implement advanced techniques in deep learning. We will minimally adapt the code to fit our streamlined API from the previous labs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's download our data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "remote_url = 'https://download.pytorch.org/tutorial/hymenoptera_data.zip'\n",
    "\n",
    "local_file = './data/hymenoptera_data.zip'\n",
    "os.makedirs('./data', exist_ok=True)\n",
    "\n",
    "data = requests.get(remote_url)\n",
    "\n",
    "# Save file data to local copy\n",
    "with open(local_file, 'wb')as file:\n",
    "    file.write(data.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and extract it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "  \n",
    "# opening the zip file in READ mode\n",
    "with ZipFile(local_file, 'r') as zip:\n",
    "    # printing all the contents of the zip file\n",
    "    zip.printdir()\n",
    "  \n",
    "    # extracting all the files\n",
    "    print('Extracting all the files now...')\n",
    "    zip.extractall('./data')\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can work with this data directly using `torchvision`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "train_transform = T.Compose([\n",
    "    T.RandomResizedCrop(224),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform =  T.Compose([\n",
    "    T.Resize(256),\n",
    "    T.CenterCrop(224),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "data_dir = 'data/hymenoptera_data'\n",
    "train_dataset = torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'), train_transform)\n",
    "test_dataset = torchvision.datasets.ImageFolder(os.path.join(data_dir, 'val'), test_transform)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=4)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=4, shuffle=True, num_workers=4)\n",
    "\n",
    "train_size = len(train_dataset)\n",
    "test_size = len(test_dataset)\n",
    "class_names = train_dataset.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize a few images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(train_dataloader))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two major transfer learning techniques depending on which parts of the network are updated using the new data:\n",
    "1. Finetuning the full network\n",
    "2. Finetuning only the last layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetuning the full network\n",
    "Instead of random initialization, we initialize the network with a pretrained network, like the one that is trained on imagenet 1000 dataset. The rest of the training looks as usual, albeit normally using a significantly smaller learning rate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinetuningFullModel(BasicModel):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.network = torchvision.models.resnet18(pretrained=True)\n",
    "        num_ftrs = self.network.fc.in_features\n",
    "        self.network.fc = nn.Linear(num_ftrs, num_classes) # We need to adapt the last layer to the new number of classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FinetuningFullModel(num_classes=2).to(DEVICE)\n",
    "\n",
    "# We normally use SGD to finetune a large model\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "model.fit(\n",
    "    train_dataloader = train_dataloader,\n",
    "    optimizer = optimizer,\n",
    "    epochs = 25,\n",
    "    device = DEVICE\n",
    ")\n",
    "\n",
    "# predict with the trained model\n",
    "model.predict(\n",
    "    test_dataloader = test_dataloader,\n",
    "    device = DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetuning the last layer\n",
    "\n",
    "Sometimes finetuning all the parameters of a large model is too expensive, or unstable. In those cases, one can alternatively 'freeze' some parts of the network, and train only the latter parts. Most often, just tuning the last layer is enough to get good enough results, with the optimal performance normally achieved by finetuning a few of the last layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinetuningLastLayer(BasicModel):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.network = torchvision.models.resnet18(pretrained=True)\n",
    "        for param in self.network.parameters():\n",
    "            param.requires_grad = False # We set requires_grad=False to avoid computing gradients of those layers in the backward pass\n",
    "\n",
    "        num_ftrs = self.network.fc.in_features\n",
    "        self.network.fc = nn.Linear(num_ftrs, num_classes) # The new last layer has requires_grad=True by default\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FinetuningLastLayer(num_classes=2).to(DEVICE)\n",
    "\n",
    "# We normally use SGD to finetune a large model\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "model.fit(\n",
    "    train_dataloader = train_dataloader,\n",
    "    optimizer = optimizer,\n",
    "    epochs = 25,\n",
    "    device = DEVICE\n",
    ")\n",
    "\n",
    "# predict with the trained model\n",
    "model.predict(\n",
    "    test_dataloader = test_dataloader,\n",
    "    device = DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "272409f0e9a7fa7a56e0c9afd18235bf99c4322749562301601e350b042a1e61"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit ('3.10.0': pyenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

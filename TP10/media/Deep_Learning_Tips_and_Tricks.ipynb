{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8u2F37pU70wA"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exo4wW7570wF"
      },
      "source": [
        "# On the previous episode...\n",
        "\n",
        "On the previous lab we introduced neural network and implemented them using the `PyTorch` library. Our experiments showed that for image classification a CNN architecture yields good results on MNIST and, depending on the complexity of the network you created, \"good\" results on CIFAR10. However, dealing with MNIST someone might have gotten the wrong impression: \"everythings work out-of-the-box or like magic in Deep Learning\". Reality is not so rosy and we must go to great lengths do replicate our success on MNIST for other datasets.\n",
        "\n",
        "In this lab, we will explore common pitfalls as well as common tips and tricks to resolve them. These simple methods will provide superior performance and are very easy to incorporate in our pipeline. \n",
        "\n",
        "Specifically, we will talk about:\n",
        "* The importance of Learning Rate\n",
        "* Batch Normalization\n",
        "* Residual Connections\n",
        "\n",
        "In the next lab, we will see more cool \"tricks\". \n",
        "\n",
        "So... let's get started!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VuXUdla70wH"
      },
      "source": [
        "For convenience, we copy-paste the necessary code from the previous lab. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Umg4I_nr70wI"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "\n",
        "class BasicModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Here we define the model modules\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        # defines the forward function of the model. \n",
        "        raise NotImplementedError\n",
        "\n",
        "\n",
        "    def fit(self, train_dataloader, optimizer, epochs, device, plot_loss=True):\n",
        "        losses = []\n",
        "        for epoch in range(epochs):\n",
        "            running_loss = self.train_epoch(\n",
        "                train_dataloader=train_dataloader, \n",
        "                optimizer=optimizer, \n",
        "                epoch_idx=epoch,\n",
        "                device=device)\n",
        "            \n",
        "            losses.extend(running_loss)\n",
        "\n",
        "        if plot_loss:\n",
        "            self.plot_loss_progression(losses=losses)\n",
        "\n",
        "    def plot_loss_progression(self, losses):\n",
        "        plt.plot(losses)\n",
        "        plt.xlabel('Steps')\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.title(\"Loss progression across steps\")\n",
        "\n",
        "    def train_epoch(self, train_dataloader, optimizer, epoch_idx, device):\n",
        "        epoch_losses = []\n",
        "        running_loss = 0.0\n",
        "\n",
        "        self.train()\n",
        "        tk0 = tqdm(train_dataloader, total=len(train_dataloader), desc=f\"Epoch {epoch_idx}\")\n",
        "        for batch_idx, (data, target) in enumerate(tk0):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            output = self(data)\n",
        "            loss = F.cross_entropy(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "            avg_loss = running_loss / (batch_idx + 1)\n",
        "            tk0.set_postfix(loss=avg_loss, stage=\"train\")\n",
        "            epoch_losses.append(loss.item())\n",
        "\n",
        "        \n",
        "        return epoch_losses\n",
        "\n",
        "\n",
        "    def predict(self, test_dataloader, device):\n",
        "        self.eval()\n",
        "        test_loss = 0\n",
        "        correct = 0\n",
        "        with torch.no_grad():\n",
        "            for data, target in test_dataloader:\n",
        "                data, target = data.to(device), target.to(device)\n",
        "\n",
        "                output = self(data)\n",
        "                loss = F.cross_entropy(output, target)\n",
        "                test_loss += loss.item()\n",
        "                pred = output.data.max(1, keepdim=True)[1]\n",
        "                correct += pred.eq(target.data.view_as(pred)).sum()\n",
        "\n",
        "        test_loss /= len(test_dataloader.dataset)\n",
        "        accuracy = 100. * correct / len(test_dataloader.dataset)\n",
        "\n",
        "        print(f'Test set: Avg. loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_dataloader.dataset)} ({accuracy:.0f}%)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e66v2Lyv70wJ"
      },
      "source": [
        "For every model we want to create, we will create a new class that inherits `BasicModel` and implemements the `__init__` and `forward` functions. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TtpmuSEY70wJ"
      },
      "outputs": [],
      "source": [
        "# first we load all the necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qY10beEa70wJ"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    # INSERT YOUR CODE HERE\n",
        "])\n",
        "\n",
        "# load the train dataset\n",
        "train_dataset = # INSERT YOUR CODE HERE\n",
        "\n",
        "# load the test dataset\n",
        "test_dataset = # INSERT YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JPV3xAk70wM",
        "outputId": "90af77af-9199-47e7-8177-a47bec5b38fb"
      },
      "outputs": [],
      "source": [
        "# define the hyperparameters\n",
        "BATCH_SIZE = 1024\n",
        "TEST_BATCH_SIZE = 1024\n",
        "LEARNING_RATE = 0.01\n",
        "\n",
        "# find out which device is available\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Im4pPN_q70wM"
      },
      "outputs": [],
      "source": [
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    dataset=train_dataset, \n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True, \n",
        "    num_workers=2)\n",
        "\n",
        "\n",
        "test_dataloader = torch.utils.data.DataLoader(\n",
        "    dataset=test_dataset, \n",
        "    batch_size=TEST_BATCH_SIZE,\n",
        "    shuffle=False, \n",
        "    num_workers=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gp7ESZ0D70wN"
      },
      "source": [
        "Now, let's visualize some samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "s_K_vHwD70wN",
        "outputId": "38d98baa-2347-4b6b-ddbb-7d93f21eef4e"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "images = next(iter(train_dataloader))[0][:10]\n",
        "grid = torchvision.utils.make_grid(images, nrow=5, padding=10)\n",
        "\n",
        "def show(img):\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n",
        "\n",
        "show(grid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVJqoRx7sQ0H"
      },
      "source": [
        "At first glance, we can see that this dataset is far more complex than MNIST."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfdycWpj70wN"
      },
      "source": [
        "## run simple model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WgtTcJGL70wN"
      },
      "outputs": [],
      "source": [
        "class CNN(BasicModel): \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # We use a Sequential, i.e. the inputs passes through each of\n",
        "        # the modules below, one-by-one\n",
        "        self.conv = nn.Sequential(         \n",
        "            nn.Conv2d(\n",
        "                in_channels= # INSERT YOUR CODE HERE,              \n",
        "                out_channels=16,            \n",
        "                kernel_size=3,              \n",
        "                stride=1,                   \n",
        "                padding=1,                  \n",
        "            ),                              \n",
        "            nn.ReLU(),                      \n",
        "            nn.MaxPool2d(kernel_size=2), \n",
        "            nn.Conv2d(\n",
        "                in_channels=16, \n",
        "                out_channels=32, \n",
        "                kernel_size=3, \n",
        "                stride=1, \n",
        "                padding=1),     \n",
        "            nn.ReLU(),                      \n",
        "            nn.MaxPool2d(2),    \n",
        "        )\n",
        "              \n",
        "        # fully connected layer, output 10 classes   \n",
        "        self.out = nn.Linear(\n",
        "            # INSERT YOUR CODE HERE, \n",
        "            10)    \n",
        "        \n",
        "    def forward(self, x):\n",
        "        # INSERT YOUR CODE HERE\n",
        "        return x   \n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "jJAe-4brCK8G",
        "outputId": "5ba23b6f-03df-43fb-ba19-0a2154656c8b"
      },
      "outputs": [],
      "source": [
        "cnn = CNN().to(DEVICE)\n",
        "optimizer = torch.optim.SGD(cnn.parameters(), lr=0.001)\n",
        "\n",
        "cnn.fit(\n",
        "    train_dataloader = train_dataloader,\n",
        "    optimizer = optimizer,\n",
        "    epochs = 10,\n",
        "    device = DEVICE\n",
        ")\n",
        "\n",
        "cnn.predict(\n",
        "    test_dataloader = test_dataloader,\n",
        "    device = DEVICE\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "ZST9Pa9SCKz6",
        "outputId": "fe2778c9-c45d-494d-ae28-7e3c2ea09210"
      },
      "outputs": [],
      "source": [
        "cnn = CNN().to(DEVICE)\n",
        "optimizer = torch.optim.SGD(cnn.parameters(), lr=0.9)\n",
        "\n",
        "cnn.fit(\n",
        "    train_dataloader = train_dataloader,\n",
        "    optimizer = optimizer,\n",
        "    epochs = 5,\n",
        "    device = DEVICE\n",
        ")\n",
        "\n",
        "cnn.predict(\n",
        "    test_dataloader = test_dataloader,\n",
        "    device = DEVICE\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9PiQCzhx_fC"
      },
      "source": [
        "# Momentum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AE-bh1Sox_Ve"
      },
      "source": [
        "In this lab we have used (mini-batch) Stochastic Gradient Descent or simply SGD. For simplicity we consider the case for only one sample. The update rule is the following:\n",
        "\n",
        "$$\n",
        "\\mathbf{w}^{(\\tau+1)} \\gets \\mathbf{w}^{(\\tau)} - \\eta\\nabla \\mathcal{L}\\left(\\mathbf{x}, y;\\mathbf{w}^{(\\tau)}\\right)\n",
        "$$\n",
        "\n",
        "How can we improve our algorithm and encourage faster convergence? Momentum can actually help. The idea is simple: we will use the update made on the previous step and incorporate it to our current update, giving momentum to our algorithm. The actual update rule is the following:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\mathbf{v}^{(\\tau+1)} &\\gets \\gamma\\mathbf{v}^{(\\tau)} + \\nabla \\mathcal{L}\\left(\\mathbf{x}, y;\\mathbf{w}^{(\\tau)}\\right)\n",
        "\\\\\n",
        "\\mathbf{w}^{(\\tau+1)} &\\gets \\mathbf{w}^{(\\tau)} - \\eta \\mathbf{v}^{(\\tau)}\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Apart from making convergence faster, momentum has other benefits:\n",
        "* dampens oscillations \n",
        "* helps us navigate ravines around local optima [1]\n",
        "\n",
        "If you are more interested in the various optimizers take a look at reference [1].\n",
        "\n",
        "----\n",
        "[1] Ruder, S., 2016. An overview of gradient descent optimization algorithms. arXiv preprint arXiv:1609.04747.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "45M-B9Z8x_Fw",
        "outputId": "19ff18ce-f778-4e22-f2d3-38bde5b6c3de"
      },
      "outputs": [],
      "source": [
        "# Let's change the \"slow\" version by simply adding momentum to the optimizer. \n",
        "# We will use the default value of \\gamma=0.9\n",
        "# What do you think will happen?\n",
        "\n",
        "cnn = CNN().to(DEVICE)\n",
        "optimizer = torch.optim.SGD(cnn.parameters(), lr=0.001, # INSERT YOUR CODE HERE)\n",
        "\n",
        "cnn.fit(\n",
        "    train_dataloader = train_dataloader,\n",
        "    optimizer = optimizer,\n",
        "    epochs = 10,\n",
        "    device = DEVICE\n",
        ")\n",
        "\n",
        "cnn.predict(\n",
        "    test_dataloader = test_dataloader,\n",
        "    device = DEVICE\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGyceXYl70wP"
      },
      "source": [
        "# Batch normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keETaVfyhTHo"
      },
      "source": [
        "We want to learn fast and converge at the same time. If we use a small learning rate, we will converge but it will be too slow. On the other hand, if we use large learning rate, our training will become inconsistent and we will bounce all over the place and never converge. Additionaly, higher learning rates  cause exploding or vanishing gradients i.e. the phenomenon where the multiplication of gradients via the chain rule induces a compound effect on the lower layers, preventing them from learning.\n",
        "\n",
        "Can we have the best of both worlds? Enter **Batch Normalization**.\n",
        "\n",
        "1. What does BatchNorm aims to solve? We want to\n",
        "    * avoid unstable gradients,\n",
        "    * allow faster learning rates leading to faster convergence,\n",
        "    * reduce the effect of initialization.\n",
        "\n",
        "2. Why does BatchNorm actually do?\n",
        "    * Suppose we are given values of $x$ over a mini-batch $\\mathcal{B}=\\{x_i\\}_{i=1}^m$. Our goal is to learn some parameters $\\gamma$ and $\\beta$ that perform the proper scaling.\n",
        "\n",
        "    * First, we compute the mini-batch mean\n",
        "    $$\n",
        "    \\mu_{\\mathcal{B}}=\\frac{1}{m}\\sum_{i=1}^mx_i\n",
        "    $$\n",
        "    * and mini-batch variance\n",
        "    $$\n",
        "    \\sigma^2_{\\mathcal{B}}=\\frac{1}{m}\\sum_{i=1}^m (x_i-\\mu_{\\mathcal{B}})^2\n",
        "    $$\n",
        "    * we use these quantities to normalize our input\n",
        "    $$\n",
        "    \\hat{x}_i=\\frac{x_i-\\mu_{\\mathcal{B}}}{\\sqrt{\\sigma^2_{\\mathcal{B}}+\\epsilon}}\n",
        "    $$\n",
        "    * We scale, shift and return the output\n",
        "    $$\n",
        "    y_i=\\gamma \\hat{x}_i+\\beta\\equiv \\text{BN}_{\\gamma, \\beta}(x_i)\n",
        "    $$\n",
        "    * Essentially, for each mini-batch we normalize the inputs by subtracting their mean and dividing by their standard deviation (estimated based on the statistics of the current mini-batch)  \n",
        "\n",
        "\n",
        "3. Why does BatchNorm work?\n",
        "\n",
        "    * BatchNorm is widely used (e.g. the original paper [1] has over 30000 citations). However, the reasons of its success are not perfectly clear.\n",
        "    * The original authors claim that BatchNorm helps alleviate *Internal Covariate shift*, i.e. the phenomenon of shifting input distributions. Specifically, the input to each layer can be seen as a data distribution that the layer is trying to “learn”. The model, though, does not see the whole dataset but simply mini-batches. If this distribution stays consistent across batches, the layer can \"learn effectively\".  But, does this happen in practice?\n",
        "    * the reality is that different mini-batches have different statistics, e.g. mean, variance etc, making the input distribution to the layers jump around. In other words, the input distribuion shifts for every mini-batch. We are trying to learn a \"moving target\". What if we stabilize it?\n",
        "    * Batch normalization keeps the input normalized (duh!), preventing them from becoming too large or small and keeping the distribution consistent. \n",
        "    \n",
        "    * It also directly placates the exploding/vanishing gradient problem and  allows higher learning rates.\n",
        "\n",
        "    * However, other explanations have been proposed. [2] claims that BatchNorm \"makes the optimization landscape significantly smoother. This smoothness induces a more predictive and stable behavior of the gradients, allowing for faster training\".\n",
        "\n",
        "\n",
        "---\n",
        "[1] S. Ioffe and C. Szegedy, “Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift,” in Proceedings of the 32nd International Conference on Machine Learning, Jun. 2015, pp. 448–456. Accessed: Oct. 25, 2021. [Online]. Available: https://proceedings.mlr.press/v37/ioffe15.html\n",
        "\n",
        "[2] S. Santurkar, D. Tsipras, A. Ilyas, and A. Madry, “How Does Batch Normalization Help Optimization?,” in Advances in Neural Information Processing Systems, 2018, vol. 31. Accessed: Oct. 25, 2021. [Online]. Available: https://papers.nips.cc/paper/2018/hash/905056c1ac1dad141560467e0a99e1cf-Abstract.html\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "PQm5F_CAEtOK",
        "outputId": "eb16a2df-3fd0-411f-f2d4-f4c3a7cca0d7"
      },
      "outputs": [],
      "source": [
        "# we make the Batch_sizes smaller for computational reasons\n",
        "# we will later use larger models and memory might become an issue\n",
        "BATCH_SIZE = 256\n",
        "TEST_BATCH_SIZE = 256\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# load the train dataset\n",
        "train_dataset = torchvision.datasets.CIFAR10(\n",
        "    root='./data/', \n",
        "    train=True, \n",
        "    download=True,\n",
        "    transform=transform)\n",
        "\n",
        "# load the test dataset\n",
        "test_dataset = torchvision.datasets.CIFAR10(\n",
        "    root='./data/', \n",
        "    train=False, \n",
        "    download=True,\n",
        "    transform=transform)\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    dataset=train_dataset, \n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True, \n",
        "    num_workers=2)\n",
        "\n",
        "\n",
        "test_dataloader = torch.utils.data.DataLoader(\n",
        "    dataset=test_dataset, \n",
        "    batch_size=TEST_BATCH_SIZE,\n",
        "    shuffle=False, \n",
        "    num_workers=2)\n",
        "\n",
        "\n",
        "images = next(iter(train_dataloader))[0][:10]\n",
        "grid = torchvision.utils.make_grid(images, nrow=5, padding=10)\n",
        "\n",
        "show(grid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFJQwobQEpvC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8muCisTyEz4Q"
      },
      "outputs": [],
      "source": [
        "# redo the previous cnn architecture with batch normalization\n",
        "# where does the batch normalization go?\n",
        "class CNN_Cifar10(BasicModel): \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # We use a Sequential, i.e. the inputs passes through each of\n",
        "        # the modules below, one-by-one\n",
        "        self.conv = nn.Sequential(         \n",
        "            nn.Conv2d(\n",
        "                in_channels=# INSERT YOUR CODE HERE,              \n",
        "                out_channels=16,            \n",
        "                kernel_size=3,              \n",
        "                stride=1,                   \n",
        "                padding=1,                  \n",
        "            ),                              \n",
        "            nn.ReLU(),                      \n",
        "            nn.MaxPool2d(kernel_size=2), \n",
        "            nn.Conv2d(\n",
        "                in_channels=16, \n",
        "                out_channels=32, \n",
        "                kernel_size=3, \n",
        "                stride=1, \n",
        "                padding=1),     \n",
        "            nn.ReLU(),                      \n",
        "            nn.MaxPool2d(2),    \n",
        "        )\n",
        "              \n",
        "        # fully connected layer, output 10 classes\n",
        "        self.out = nn.Linear(# INSERT YOUR CODE HERE, 10)       \n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = x.view(x.size(0), -1) \n",
        "        x = self.out(x)\n",
        "        return x   \n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eOovZfM2GNzT",
        "outputId": "b34de0dd-b374-4d64-ac72-e73f6b62dee9"
      },
      "outputs": [],
      "source": [
        "cnn = CNN_Cifar10().to(DEVICE)\n",
        "optimizer = torch.optim.SGD(cnn.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "cnn.fit(\n",
        "    train_dataloader = train_dataloader,\n",
        "    optimizer = optimizer,\n",
        "    epochs = 50,\n",
        "    device = DEVICE\n",
        ")\n",
        "\n",
        "cnn.predict(\n",
        "    test_dataloader = test_dataloader,\n",
        "    device = DEVICE\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZxZnhC9VYdM"
      },
      "outputs": [],
      "source": [
        "class CNNwithBN(BasicModel): \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # We use a Sequential, i.e. the inputs passes through each of\n",
        "        # the modules below, one-by-one\n",
        "        \n",
        "        # take the previous CNN and add batch norm. \n",
        "        # Where should the BN be added?\n",
        "        self.conv = # INSERT YOUR CODE HERE\n",
        "              \n",
        "        # fully connected layer, output 10 classes\n",
        "        self.out = nn.Linear(2048, 10)       \n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = x.view(x.size(0), -1) \n",
        "        x = self.out(x)\n",
        "        return x   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wvX2kUDhV3Th",
        "outputId": "9738750f-bd87-46b1-e9ef-7d1a7347da66"
      },
      "outputs": [],
      "source": [
        "cnn2 = CNNwithBN().to(DEVICE)\n",
        "optimizer = torch.optim.SGD(cnn2.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "cnn2.fit(\n",
        "    train_dataloader = train_dataloader,\n",
        "    optimizer = optimizer,\n",
        "    epochs = 50,\n",
        "    device = DEVICE\n",
        ")\n",
        "\n",
        "cnn2.predict(\n",
        "    test_dataloader = test_dataloader,\n",
        "    device = DEVICE\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myX7KAesWeaF"
      },
      "source": [
        "One of the benefits of Batch Norm is that it allows us to use higher learning rates. Adapt the code above to do so. Does the model learn faster?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vt1fMrPIEp1e",
        "outputId": "51b70a28-e80d-410e-97eb-f99ebc485998"
      },
      "outputs": [],
      "source": [
        "cnn2 = CNNwithBN().to(DEVICE)\n",
        "optimizer = torch.optim.SGD(cnn2.parameters(), lr=0.05, momentum=0.9)\n",
        "\n",
        "cnn2.fit(\n",
        "    train_dataloader = train_dataloader,\n",
        "    optimizer = optimizer,\n",
        "    epochs = 50,\n",
        "    device = DEVICE\n",
        ")\n",
        "\n",
        "cnn2.predict(\n",
        "    test_dataloader = test_dataloader,\n",
        "    device = DEVICE\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-jpcEJU70wP"
      },
      "source": [
        "# Residual connections\n",
        "\n",
        "As neural networks go deeper, they are able to construct complex representations and yield superior performance. However, we cannot simply stack as many layers as we want to increase the depth. \n",
        "\n",
        "![caption](media/resnet-no-skip-horizontal.png)\n",
        "\n",
        "This is due to the **vanishing gradient** problem. Specifically, backpropagating the gradient to earlier layers involves repeated multiplication (with small values) rendering the gradient extremely small. This effectively means that as we go deeper, performance gets saturated. Instead of improved performance we even have degradation!\n",
        "\n",
        "How can we reconcile this tradeoff? On the one hand, we want to increase depth but on the other hand this hurts convergence. \n",
        "\n",
        "Enter **skip connections** [3]! The network of the previous figure now becomes the following:\n",
        "\n",
        "![caption](media/resnet-horizontal.png)\n",
        "\n",
        "Now, let's think why these skip connections work. First, they allow the gradient to flow via this shortcut connection, which helps mitigate the problem of vanishing gradient. Second, they allow the model to learn the identity function. In other words, this ensures that the higher layer will perform at least as good as the lower layer.\n",
        "\n",
        "---\n",
        "[3] K. He, X. Zhang, S. Ren, and J. Sun, “Deep Residual Learning for Image Recognition,” in 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Las Vegas, NV, USA, Jun. 2016, pp. 770–778. doi: 10.1109/CVPR.2016.90.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoeJeLQ8bZMi"
      },
      "source": [
        "First, we build the network of the first image, i.e. with no skip connections. The Resnet depicted above is characterized by an interesting pattern. It consists of \"super-blocks\" (see the different colors) and each one consists of two blocks that start after one residual connection and finish just before one. Notice that each color is associated with a different number, i.e. 64, 128, 256, 512. \n",
        "\n",
        "We will build a `nn.Module` for each block and repeat it to create the super-blocks and by extension the whole architecture.\n",
        "\n",
        "The ResNet depicted above is meant to be used for `ImageNet`, a more complex dataset compared to `CIFAR10`. For computational considerations, we amend our implementation and make a simpler version."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "626cjZVwa7HD"
      },
      "outputs": [],
      "source": [
        "class WrongBlock(nn.Module):\n",
        "    \n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels = in_planes,\n",
        "            out_channels = planes, \n",
        "            kernel_size=3, \n",
        "            stride=stride, \n",
        "            padding=1, \n",
        "            bias=False)\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            planes, \n",
        "            planes, \n",
        "            kernel_size=3,\n",
        "            stride=1, \n",
        "            padding=1, \n",
        "            bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class ResNet(BasicModel):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes \n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "W2AoqF0ra7HG",
        "outputId": "ab22ca68-6bdd-41da-ede1-2beca8bd9aa9"
      },
      "outputs": [],
      "source": [
        "# initialize the model \n",
        "model = ResNet(block=WrongBlock, num_blocks=[2,2,2,2]).to(DEVICE)\n",
        "\n",
        "# define the optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# train the ResNet\n",
        "model.fit(\n",
        "    train_dataloader = train_dataloader,\n",
        "    optimizer = optimizer,\n",
        "    epochs = 30,\n",
        "    device = DEVICE\n",
        ")\n",
        "\n",
        "# predict with the trained model\n",
        "model.predict(\n",
        "    test_dataloader = test_dataloader,\n",
        "    device = DEVICE\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQHjjbs2fEQz"
      },
      "source": [
        "How many layers does the above model have?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCbe7tlbbRvM"
      },
      "source": [
        "Now, we add skip connections. Notice that sometimes the skip connection cannot be simply an identity function, since the dimensions will not match. Identify the condition when this is necessary. In that case, the shortcut function should be a convolution followed by BatchNorm. \n",
        "\n",
        "Fill the code below!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBEe9QiT70wQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "class CorrectBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        # take a look at self.shortcut. Why is the if-statement necessary?\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # INSERT YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DshRz_870wQ",
        "outputId": "5e31d353-d744-4862-f87e-9d92a8ee4b08"
      },
      "outputs": [],
      "source": [
        "# initialize the model using the CorrectBlock module you created\n",
        "model = ResNet(block=CorrectBlock, num_blocks=[2,2,2,2]).to(DEVICE)\n",
        "\n",
        "# define the optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# train the ResNet\n",
        "model.fit(\n",
        "    train_dataloader = train_dataloader,\n",
        "    optimizer = optimizer,\n",
        "    epochs = 30,\n",
        "    device = DEVICE\n",
        ")\n",
        "\n",
        "# predict with the trained model\n",
        "model.predict(\n",
        "    test_dataloader = test_dataloader,\n",
        "    device = DEVICE\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZdrTS4rm6u8"
      },
      "outputs": [],
      "source": [
        "# Let's take a look at our model\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_lhdhcjdehm6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Deep Learning Tips and Tricks-orig.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
    },
    "kernelspec": {
      "display_name": "Python 3.8.3 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
